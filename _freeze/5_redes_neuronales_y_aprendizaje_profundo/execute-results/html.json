{
  "hash": "86f0074b86be25f382d9c294924b1df0",
  "result": {
    "markdown": "# Redes neurales\n\n## Perceptrón y redes neuronales\n\nEl perceptrón en el modelo más secillo de las neuronas. Se le llama también *neurona artificial*.\n\n![](./figuras/MLP01.svg){fig-align=\"center\"}\n\nLa idea es que cada uno de los *features* se multiplica por un peso $w_k$, se le suma un *bias* $b$ y al resultado de esta operación se le aplica la función de activación, que finalmente produce la salida $y$. Esta función de activación preferiblemente debe ser diferenciable y tres de las funciones más comunes son la función logística, la función tangente hiperbólica y la función lineal rectificada unitaria (ReLU):\n\n\\begin{equation*}\n\\text{logística: } f(x) = \\frac{1}{1+e^{-x}}\n\\end{equation*}\n\n\\begin{equation*}\n\\text{tangente hiperbólica: } f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n\\end{equation*}\n\n\\begin{equation*}\n\\text{ReLU: } f(x) = \\begin{cases}\n    0, & \\text{si } x < 0 \\\\\n    x, & \\text{en otro caso}\n\\end{cases}\n\\end{equation*}\n\nEn sí, el perceptrón es clasificador muy similar a la regresión logística. Sin embargo, es muy poco común que se utilice un solo perceptrón, sino que se utiliza varias capas (*layers*) de múltiples perceptrones, de manera que se pueda clasificar casos más complejos, a esto se le llama Perceptrón de capas múltiples (*Multiple Layer Perceptron*, MLP).\n\nUna capa está compuesta por varios perceptrones que están conectados con las entradas o con las salidas de la capa anterior, tal y como se muestra en la figura siguiente:\n\n![](./figuras/MLP02.svg){fig-align=\"center\"}\n\ncada uno de los bloques $P_{ij}$ es un perceptrón. En la figura, solo se tiene una salida, pero bien podría tenerse más, por lo que la capa de salida podría tener más de un perceptrón. De igual manera, se puede tener más de una capa escondida.\n\nLo que se debe hacer ahora es que, a partir de los datos que se tienen, encontrar los valores de los pesos $w_k$ y $b_k$, es decir, entrenar a la red.\n\n## Entrenamiento de la red neuronal\n\nPara entrenar la red, se debe buscar los valores. Para ello se minimiza una función de costo, como por ejemplo el error cuadrático medio.\n\n Para lograr la optimización se suele utilizar el descenso del gradiente, en un algoritmo llamado *Backpropagation*. Con el Backpropagation se calcula  el gradiente de la función de costo con respecto a los pesos de la red, de una manera eficiente. Se calculan el gradiente una capa a la vez , iterando hacia atrás desde la última capa.\n\n## Comandos en python\n\nCon la libraría scikit se puede crear y entrenar fácilmente una red neuronal.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.neural_network import MLPClassifier\n\n# Acá se cargan los datos\nX = [[0., 0.], [1., 1.]] # acá se pondría una lista de listas con los featrures\nY = [0, 1] # acá los labels\n\n# Acá se crea la red\nclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n\n# Acá se entrena la red\nclf.fit(X, Y)\n\n# Y acá se utiliza la red para predecir el valor de la salida para una nueva entrada\nclf.predict([[-1., -2.]])\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\narray([0])\n```\n:::\n:::\n\n\nen la variable **hidden_layer_sizes** se pone el número de perceptrones para cada una de las capas escondidas. **alpha** es la fuerza del término de regularización L2. El solver es el algoritmo de optimización:\n\n* `lbfgs` es un optimizador de la familia de métodos cuasi-Newton.\n* `sgd` se refiere al descenso estocástico del gradiente.\n* `adam` se refiere al optimizador estocástico del gradiente propuesto por Kingma, Diederik, and Jimmy Ba.\n\n",
    "supporting": [
      "5_redes_neuronales_y_aprendizaje_profundo_files"
    ],
    "filters": [],
    "includes": {}
  }
}